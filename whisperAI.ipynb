{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 음성 파일 불러온 후, Word 파일 형식으로 저장 (audio2text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lPs46BvAiL11",
        "outputId": "7d85e227-58a0-47a4-d200-be48799c7b56"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!pip install python-docx\n",
        "!sudo apt update && sudo apt install ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09CP689hwUAz",
        "outputId": "fa9585ad-d35d-4958-f322-884a07915d1f"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YI4oECWQjij0"
      },
      "outputs": [],
      "source": [
        "import whisper\n",
        "import os\n",
        "from docx import Document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJcfk-SnjaNw"
      },
      "outputs": [],
      "source": [
        "audio_file_path = \"/content/drive/MyDrive/audio/\"\n",
        "\n",
        "audio_files_name = [f for f in os.listdir(audio_file_path) if f.endswith('.m4a')]\n",
        "\n",
        "audio_files_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eyi9PwqAnGDv"
      },
      "outputs": [],
      "source": [
        "audio_files_path = [os.path.join(audio_file_path, f) for f in audio_files_name]\n",
        "\n",
        "audio_files_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxg-vNidiPyF"
      },
      "outputs": [],
      "source": [
        "# Whisper 모델 로드 (large 모델 사용)\n",
        "model = whisper.load_model(\"large\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dOB6Lf9gjt37"
      },
      "outputs": [],
      "source": [
        "sava_file_path = \"/content/drive/MyDrive/audio/\"\n",
        "\n",
        "for audio_file in audio_files_path:\n",
        "  result = model.transcribe(audio_file, task=\"transcribe\")\n",
        "\n",
        "  transcribed_text = result[\"text\"]\n",
        "  base_filename = audio_file.split('/')[-1].split('.')[0]\n",
        "\n",
        "  doc = Document()\n",
        "  doc.add_paragraph(transcribed_text)\n",
        "  doc.save(f\"{sava_file_path}/{base_filename}.docx\")\n",
        "\n",
        "\n",
        "  print(f\"Transcription saved for {audio_file} as Word files.\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

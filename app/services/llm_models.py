from app.common.config import whisperAI_MODEL_NAME, OPENAI_API_KEY

import sys
import openai
import whisper
import whisper.utils

from app.errors import exceptions as ex
from app.errors.exceptions import APIException, FailLoadLLM


from contextlib import asynccontextmanager

whisperAI_model = None

client = openai.OpenAI(
        api_key=OPENAI_API_KEY,
    )


def VideoTitleEditer(sentences):
    response = client.chat.completions.create(
        model= "gpt-4o-mini",
        messages=[
            {"role": "system",
             "content":"""ë‹¹ì‹ ì€ ìœ íŠœë¸Œ ì˜ìƒ ì œëª©ì„ ìë™ìœ¼ë¡œ ìˆ˜ì •í•˜ëŠ” AIì…ë‹ˆë‹¤.
             ì‚¬ìš©ìê°€ ì œê³µí•œ ì œëª©ì—ì„œ ë¹ˆ ì¹¸, í°ë”°ì˜´í‘œ("), íŠ¹ìˆ˜ ë¬¸ì(â€œ) ë“±ì„ ì œê±°í•˜ê³ , ì˜ë¯¸ëŠ” ìœ ì§€í•˜ë©´ì„œ ìì—°ìŠ¤ëŸ½ê²Œ ìˆ˜ì •í•˜ì„¸ìš”.
             ê°€ëŠ¥í•œ í•œ ì›ë³¸ ì œëª©ê³¼ ìœ ì‚¬í•œ í˜•íƒœë¥¼ ìœ ì§€í•˜ë˜, í•„ìš”í•œ ê²½ìš° ëŒ€ì²´ ë¬¸ìë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
             """},
             {"role": "user", "content": f"{sentences}"}],
        temperature = 0.1,
        top_p = 0.1
    )
    response_ = response.choices[0].message.content
    return response_


@asynccontextmanager
async def lifespan(app):
    global whisperAI_model
    try:
        # whisperAI_MODEL_NAME = "except_test" # LLM ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ í…ŒìŠ¤íŠ¸ ì½”ë“œ
        whisperAI_model = whisper.load_model(f"{whisperAI_MODEL_NAME}")
        print("ğŸš© whisper ëª¨ë¸ ë¡œë“œ")
    except Exception as e:
        raise ex.FailLoadLLM()

    yield
    print("ğŸš© whisper ëª¨ë¸ ë¡œë“œ í•´ì œ")